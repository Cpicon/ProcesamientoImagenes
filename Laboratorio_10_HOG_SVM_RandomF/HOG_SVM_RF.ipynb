{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se importan las librerias\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import glob\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "import skimage.io as io\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se obtienen las direcciones del sistema para el workspace actual\n",
    "current_directory = os.getcwd()\n",
    "# se cargan las rutas de las imagenes de entrenamiento y validación\n",
    "train_paths = glob.glob(os.path.join(current_directory,'train','*.jpg'))\n",
    "valid_paths = glob.glob(os.path.join(current_directory,'val','*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se construye el vector de etiquetas para las imagenes de entrenamiento y valicion\n",
    "# 0 means dafodil\n",
    "# 1 means snowdrop\n",
    "# 2 means sunflower\n",
    "# 3 means tigerlily\n",
    "labels_train = [0]*5 + [1]*5 + [2]*5 + [3]*5 \n",
    "labels_valid= [0]*5 + [1]*5 + [2]*5 + [3]*5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se leen las imagenes alojadas en las rutas especificadas\n",
    "imagenes_train = []\n",
    "for file_train in train_paths:\n",
    "    img_train = io.imread(file_train)\n",
    "    image_rescaled_train = resize(img_train, (150,150), anti_aliasing=False)# se reduce el tamaño de las imagenes\n",
    "    imagenes_train.append(image_rescaled_train)\n",
    "\n",
    "imagenes_valid = []\n",
    "for file_valid in valid_paths:\n",
    "    img_valid = plt.imread(file_valid)\n",
    "    image_rescaled_valid = resize(img_valid, (150,150), anti_aliasing=False)# se reduce el tamaño de las imagenes\n",
    "    imagenes_valid.append(image_rescaled_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run JointColorHistogram.py\n",
    "\"\"\" Joint histogram for color images\n",
    "    code by Maria Fernanda Roa\n",
    "    mf.roa@uniandes.edu.co\n",
    "    IBIO 3470 - Uniandes \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "def JointColorHistogram(img, num_bins, min_val=None, max_val=None):\n",
    "    \"\"\"Calculate joint histogram for color images\n",
    "\n",
    "    Arguments:\n",
    "        img (numpy.array) -- 2D color image \n",
    "        num_bins (array like of ints) -- Number of bins per channel. \n",
    "                                         If an int is given, all channels\n",
    "                                         will have same ammount of bins.\n",
    "\n",
    "    Keyword Arguments:\n",
    "        min_val (array like of ints) -- Minimum intensity range value per channel\n",
    "                                        If an int is given, all channels\n",
    "                                        will have same minimmum. (default: {None})\n",
    "        max_val (array like of ints) -- Maximum intensity range value per channel\n",
    "                                        If an int is given, all channels\n",
    "                                        will have same maximum. (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [numpy.array] -- Array containing joint color histogram of size num_bins.\n",
    "    \"\"\"   \n",
    "\n",
    "    assert len(img.shape) == 3, 'img must be a color 2D image'\n",
    "    #Transform image to float dtype \n",
    "    img = img_as_float(img)\n",
    "    _, _, n_channels = img.shape\n",
    "\n",
    "    #Verify input parameters\n",
    "    assert isinstance(num_bins, (int, tuple, list, np.array)),'num_bins must be int or array like'\n",
    "    if isinstance(num_bins, int):\n",
    "        num_bins = np.array([num_bins]*n_channels)\n",
    "    assert len(num_bins) == n_channels,'num_bins length and number of channels differ'\n",
    " \n",
    "    if min_val is None:\n",
    "        min_val = np.min(img, (0,1))\n",
    "    else:\n",
    "        assert isinstance(min_val, (int, tuple, list, np.array)),'min_val must be int or array like'\n",
    "        if isinstance(min_val, int):\n",
    "            min_val = np.array([min_val]*n_channels)\n",
    "        else: \n",
    "            min_val = np.array(min_val)\n",
    "    assert len(min_val) == n_channels,'min_val length and number of channels differ'\n",
    "    min_val = min_val.reshape((1, 1, -1))\n",
    "\n",
    "    if max_val is None:\n",
    "        max_val = np.max(img, (0,1))\n",
    "    else:\n",
    "        assert isinstance(max_val, (int, tuple, list, np.array)),'max_val must be int or array like'\n",
    "        if isinstance(max_val, int):\n",
    "            max_val = np.array([max_val]*n_channels)\n",
    "        else: \n",
    "            max_val = np.array(max_val)\n",
    "    assert len(max_val) == n_channels,'max_val length and number of channels differ'\n",
    "    max_val = max_val.reshape((1, 1, -1)) + 1e-5\n",
    "\n",
    "    joint_hist = np.zeros(num_bins, dtype=np.int)\n",
    "    num_bins = num_bins.reshape((1, 1, -1))\n",
    "\n",
    "    # Scale intensities (intensities are scaled within the range for each channel)\n",
    "    # Values now are between 0 and 1\n",
    "    img = (img - min_val) / (max_val - min_val)\n",
    "    # Calculate index matrix \n",
    "    idx_matrix = np.floor(img*num_bins).astype('int') \n",
    "    idx_matrix = idx_matrix.reshape((-1, n_channels))\n",
    "    #Create joint histogram\n",
    "    for p in range(len(idx_matrix)):\n",
    "        joint_hist[tuple(idx_matrix[p, :])] += 1\n",
    "\n",
    "    return joint_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se obtienen los histogramas conjuntos de las imagenes de entranamiento y validacion\n",
    "hist1_train = []\n",
    "hist2_train = []\n",
    "hist3_train = []\n",
    "for img_train in imagenes_train:\n",
    "    hist1_train.append(JointColorHistogram(img_train, 100).ravel())# para 100 bins\n",
    "    hist2_train.append(JointColorHistogram(img_train, 200).ravel())# para 200 bins\n",
    "    hist3_train.append(JointColorHistogram(img_train, 255).ravel())# para 255 bins\n",
    "\n",
    "hist1_train = np.array(hist1_train)    \n",
    "hist2_train = np.array(hist2_train)  \n",
    "hist3_train = np.array(hist3_train)  \n",
    "\n",
    "hist1_valid = []\n",
    "hist2_valid = []\n",
    "hist3_valid = []\n",
    "for img_valid in imagenes_valid:\n",
    "    hist1_valid.append(JointColorHistogram(img_valid, 100).ravel())# para 100 bins\n",
    "    hist2_valid.append(JointColorHistogram(img_valid, 200).ravel())# para 200 bins\n",
    "    hist3_valid.append(JointColorHistogram(img_valid, 255).ravel())# para 255 bins\n",
    "    \n",
    "hist1_valid = np.array(hist1_valid)    \n",
    "hist2_valid = np.array(hist2_valid)  \n",
    "hist3_valid = np.array(hist3_valid)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.65 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist1 = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist1.fit(hist1_train,labels_train)\n",
    "labels_predict1 = sv_linear_hist1.predict(hist1_valid)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(sv_linear_hist1.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6 to 200 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist2 = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist2.fit(hist2_train,labels_train)\n",
    "labels_predict2 = sv_linear_hist2.predict(hist2_valid)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 200 bins\".format(sv_linear_hist2.score(hist2_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6 to 255 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist3 = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist3.fit(hist3_train,labels_train)\n",
    "labels_predict3 = sv_linear_hist3.predict(hist3_valid)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 255 bins\".format(sv_linear_hist3.score(hist3_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.35 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(verbose= False)\n",
    "rf1.fit(hist1_train,labels_train)\n",
    "labels_predict1_rf = rf1.predict(hist1_valid)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(rf1.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.4 to 200 bins\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(verbose= False)\n",
    "rf2.fit(hist2_train,labels_train)\n",
    "labels_predict2_rf = rf2.predict(hist2_valid)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 200 bins\".format(rf2.score(hist2_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5 to 255 bins\n"
     ]
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(verbose= False)\n",
    "rf3.fit(hist3_train,labels_train)\n",
    "labels_predict3_rf = rf3.predict(hist3_valid)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 255 bins\".format(rf3.score(hist3_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se obtienen los hog de las imagenes de entrenamiento y validacion\n",
    "hist1_train_hog = []\n",
    "hist2_train_hog = []\n",
    "hist3_train_hog = []\n",
    "hist4_train_hog = []\n",
    "for img_train in imagenes_train:\n",
    "    hist1_train_hog.append(hog(img_train, 8,feature_vector = True))# con 8 bins para orientaciones\n",
    "    hist2_train_hog.append(hog(img_train, 24, feature_vector = True))# con 24 bins para orientaciones\n",
    "    hist3_train_hog.append(hog(img_train, 8, cells_per_block=(7,7),feature_vector = True))# con 8 bins para orientaciones y 7 bloques\n",
    "    hist4_train_hog.append(hog(img_train, 8, cells_per_block=(14,14),feature_vector = True))# con 8 bins para orientaciones y 14 bloques\n",
    "\n",
    "hist1_train_hog = np.array(hist1_train_hog)    \n",
    "hist2_train_hog = np.array(hist2_train_hog)  \n",
    "hist3_train_hog = np.array(hist3_train_hog)  \n",
    "hist4_train_hog = np.array(hist4_train_hog)\n",
    "\n",
    "hist1_valid_hog = []\n",
    "hist2_valid_hog = []\n",
    "hist3_valid_hog = []\n",
    "hist4_valid_hog = []\n",
    "for img_valid in imagenes_valid:\n",
    "    hist1_valid_hog.append(hog(img_valid, 8,feature_vector = True))# con 8 bins para orientaciones\n",
    "    hist2_valid_hog.append(hog(img_valid, 24, feature_vector = True))# con 24 bins para orientaciones\n",
    "    hist3_valid_hog.append(hog(img_valid, 8, cells_per_block=(7,7),feature_vector = True))# con 8 bins para orientaciones y 7 bloques\n",
    "    hist4_valid_hog.append(hog(img_valid, 8, cells_per_block=(14,14),feature_vector = True))# con 8 bins para orientaciones y 14 bloques\n",
    "    \n",
    "hist1_valid_hog = np.array(hist1_valid_hog)    \n",
    "hist2_valid_hog = np.array(hist2_valid_hog)  \n",
    "hist3_valid_hog = np.array(hist3_valid_hog)  \n",
    "hist4_valid_hog = np.array(hist4_valid_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.75 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist1_HOG = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist1_HOG.fit(hist1_train_hog,labels_train)\n",
    "labels_predict1_svm_hog = sv_linear_hist1_HOG.predict(hist1_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(sv_linear_hist1_HOG.score(hist1_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.75 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist2_HOG = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist2_HOG.fit(hist2_train_hog,labels_train)\n",
    "labels_predict2_svm_hog = sv_linear_hist2_HOG.predict(hist2_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(sv_linear_hist2_HOG.score(hist2_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist3_HOG = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist3_HOG.fit(hist3_train_hog,labels_train)\n",
    "labels_predict3_svm_hog = sv_linear_hist3_HOG.predict(hist3_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(sv_linear_hist3_HOG.score(hist3_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear_hist4_HOG = SVC(kernel='linear', verbose= False)\n",
    "sv_linear_hist4_HOG.fit(hist4_train_hog,labels_train)\n",
    "labels_predict4_svm_hog = sv_linear_hist4_HOG.predict(hist4_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(sv_linear_hist4_HOG.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.65 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_hog = RandomForestClassifier(verbose= False)\n",
    "rf1_hog.fit(hist1_train_hog,labels_train)\n",
    "labels_predict1_rf_hog = rf1_hog.predict(hist1_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(rf1_hog.score(hist1_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf2_hog = RandomForestClassifier(verbose= False)\n",
    "rf2_hog.fit(hist2_train_hog,labels_train)\n",
    "labels_predict2_rf_hog = rf2_hog.predict(hist2_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(rf2_hog.score(hist2_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf3_hog = RandomForestClassifier(verbose= False)\n",
    "rf3_hog.fit(hist3_train_hog,labels_train)\n",
    "labels_predict3_rf_hog = rf3_hog.predict(hist3_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(rf3_hog.score(hist3_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.75 to 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf4_hog = RandomForestClassifier(verbose= False)\n",
    "rf4_hog.fit(hist4_train_hog,labels_train)\n",
    "labels_predict4_rf_hog = rf4_hog.predict(hist4_valid_hog)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} to 100 bins\".format(rf4_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos de SVM variando el kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.35 con RBF kernel en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_rbf1_hist = SVC(kernel='rbf', verbose= False)\n",
    "sv_rbf1_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con RBF kernel en histograma conjunto de 100 bins\".format(sv_rbf1_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.85 con RBF kernel en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "sv_rbf1_hog = SVC(kernel='rbf', verbose= False)\n",
    "sv_rbf1_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con RBF kernel en hog de 8 bins\".format(sv_rbf1_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.65 con linear kernel en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear1_hist = SVC(kernel='linear', verbose= False)\n",
    "sv_linear1_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con linear kernel en histograma conjunto de 100 bins\".format(sv_linear1_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8 con linear kernel en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "sv_linear1_hog = SVC(kernel='linear', verbose= False)\n",
    "sv_linear1_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con linear kernel en hog de 8 bins\".format(sv_linear1_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos de SVM variando el la regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.55 con regularizacion de 1/10 en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_c10_hist = SVC(kernel='rbf', C= 10, verbose= False)\n",
    "sv_c10_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con regularizacion de 1/10 en histograma conjunto de 100 bins\".format(sv_c10_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9 con regularizacion de 1/10 en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "sv_c10_hog = SVC(kernel='rbf', C= 10, verbose= False)\n",
    "sv_c10_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con regularizacion de 1/10 en hog de 8 bins\".format(sv_c10_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.35 con regularizacion de 10 en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "sv_c01_hist = SVC(kernel='rbf', C= 0.1, verbose= False)\n",
    "sv_c01_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con regularizacion de 10 en histograma conjunto de 100 bins\".format(sv_c01_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.85 con regularizacion de 10 en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "sv_c01_hog = SVC(kernel='rbf', C= 0.1, verbose= False)\n",
    "sv_c01_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con regularizacion de 10 en hog de 8 bins\".format(sv_c01_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos de RF variando The number of trees in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.4 con 1000 arboles de decision en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_1000Trees_hist = RandomForestClassifier(n_estimators=1000, verbose= False)\n",
    "rf1_1000Trees_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con 1000 arboles de decision en histograma conjunto de 100 bins\".format(rf1_1000Trees_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.85 con 1000 arboles de decision en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_1000Trees_hog = RandomForestClassifier(n_estimators=1000,verbose= False)\n",
    "rf1_1000Trees_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con 1000 arboles de decision en hog de 8 bins\".format(rf1_1000Trees_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.4 con 10 arboles de decision en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_10Trees_hist = RandomForestClassifier(n_estimators=10, verbose= False)\n",
    "rf1_10Trees_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con 10 arboles de decision en histograma conjunto de 100 bins\".format(rf1_10Trees_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.85 con 10 arboles de decision en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_10Trees_hog = RandomForestClassifier(n_estimators=1000,verbose= False)\n",
    "rf1_10Trees_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con 10 arboles de decision en hog de 8 bins\".format(rf1_10Trees_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos de RF variando si hay o no boostraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.4 sin bootstrap en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_sinBT_hist = RandomForestClassifier(n_estimators=1000,bootstrap = False, verbose= False)\n",
    "rf1_sinBT_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} sin bootstrap en histograma conjunto de 100 bins\".format(rf1_sinBT_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.75 sin bootstrap en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_sinBT_hog = RandomForestClassifier(n_estimators=1000,bootstrap = False, verbose= False)\n",
    "rf1_sinBT_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} sin bootstrap en hog de 8 bins\".format(rf1_sinBT_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.45 con bootstrap en histograma conjunto de 100 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_conBT_hist = RandomForestClassifier(n_estimators=1000,bootstrap = True, verbose= False)\n",
    "rf1_conBT_hist.fit(hist1_train,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con bootstrap en histograma conjunto de 100 bins\".format(rf1_conBT_hist.score(hist1_valid, labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9 con bootstrap en hog de 8 bins\n"
     ]
    }
   ],
   "source": [
    "rf1_conBT_hog = RandomForestClassifier(n_estimators=1000,bootstrap = True, verbose= False)\n",
    "rf1_conBT_hog.fit(hist4_train_hog,labels_train)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Accuracy {} con bootstrap en hog de 8 bins\".format(rf1_conBT_hog.score(hist4_valid_hog, labels_valid)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
